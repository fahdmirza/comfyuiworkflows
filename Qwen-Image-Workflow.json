{
  "id": "91f6bbe2-ed41-4fd6-bac7-71d5b5864ecb",
  "revision": 0,
  "last_node_id": 66,
  "last_link_id": 128,
  "nodes": [
    {
      "id": 8,
      "type": "VAEDecode",
      "pos": [
        1210,
        190
      ],
      "size": [
        210,
        46
      ],
      "flags": {},
      "order": 8,
      "mode": 0,
      "inputs": [
        {
          "name": "samples",
          "type": "LATENT",
          "link": 128
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 76
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "slot_index": 0,
          "links": [
            110
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "Node name for S&R": "VAEDecode"
      },
      "widgets_values": []
    },
    {
      "id": 60,
      "type": "SaveImage",
      "pos": [
        1478.3486328125,
        190.30274963378906
      ],
      "size": [
        821.0496215820312,
        871.7067260742188
      ],
      "flags": {},
      "order": 9,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 110
        }
      ],
      "outputs": [],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.48"
      },
      "widgets_values": [
        "ComfyUI"
      ]
    },
    {
      "id": 58,
      "type": "EmptySD3LatentImage",
      "pos": [
        410.6574401855469,
        620.5468139648438
      ],
      "size": [
        270,
        106
      ],
      "flags": {},
      "order": 0,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [
            107
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "Node name for S&R": "EmptySD3LatentImage"
      },
      "widgets_values": [
        1328,
        1328,
        1
      ]
    },
    {
      "id": 7,
      "type": "CLIPTextEncode",
      "pos": [
        413,
        389
      ],
      "size": [
        425.27801513671875,
        180.6060791015625
      ],
      "flags": {},
      "order": 6,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 75
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "slot_index": 0,
          "links": [
            52
          ]
        }
      ],
      "title": "CLIP Text Encode (Negative Prompt)",
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "Node name for S&R": "CLIPTextEncode"
      },
      "widgets_values": [
        " "
      ],
      "color": "#322",
      "bgcolor": "#533"
    },
    {
      "id": 66,
      "type": "ModelSamplingAuraFlow",
      "pos": [
        418.2298278808594,
        68.82577514648438
      ],
      "size": [
        270,
        58
      ],
      "flags": {},
      "order": 4,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 126
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            125
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "Node name for S&R": "ModelSamplingAuraFlow"
      },
      "widgets_values": [
        3.500000000000001
      ]
    },
    {
      "id": 3,
      "type": "KSampler",
      "pos": [
        472.95068359375,
        154.49595642089844
      ],
      "size": [
        315,
        262
      ],
      "flags": {},
      "order": 7,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 125
        },
        {
          "name": "positive",
          "type": "CONDITIONING",
          "link": 46
        },
        {
          "name": "negative",
          "type": "CONDITIONING",
          "link": 52
        },
        {
          "name": "latent_image",
          "type": "LATENT",
          "link": 107
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "slot_index": 0,
          "links": [
            128
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "Node name for S&R": "KSampler"
      },
      "widgets_values": [
        1022313538096618,
        "randomize",
        20,
        4,
        "euler",
        "simple",
        1
      ]
    },
    {
      "id": 37,
      "type": "UNETLoader",
      "pos": [
        20,
        60
      ],
      "size": [
        346.7470703125,
        82
      ],
      "flags": {},
      "order": 1,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "slot_index": 0,
          "links": [
            126
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "Node name for S&R": "UNETLoader"
      },
      "widgets_values": [
        "qwen_image_bf16.safetensors",
        "default"
      ],
      "color": "#223",
      "bgcolor": "#335"
    },
    {
      "id": 38,
      "type": "CLIPLoader",
      "pos": [
        -11.340057373046875,
        188.20913696289062
      ],
      "size": [
        380,
        106
      ],
      "flags": {},
      "order": 2,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "CLIP",
          "type": "CLIP",
          "slot_index": 0,
          "links": [
            74,
            75
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "Node name for S&R": "CLIPLoader"
      },
      "widgets_values": [
        "qwen_2.5_vl_7b.safetensors",
        "qwen_image",
        "default"
      ],
      "color": "#223",
      "bgcolor": "#335"
    },
    {
      "id": 39,
      "type": "VAELoader",
      "pos": [
        22.686290740966797,
        359.6993713378906
      ],
      "size": [
        330,
        60
      ],
      "flags": {},
      "order": 3,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "VAE",
          "type": "VAE",
          "slot_index": 0,
          "links": [
            76
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "Node name for S&R": "VAELoader"
      },
      "widgets_values": [
        "qwen_image_vae.safetensors"
      ],
      "color": "#223",
      "bgcolor": "#335"
    },
    {
      "id": 6,
      "type": "CLIPTextEncode",
      "pos": [
        923.2462158203125,
        338.67095947265625
      ],
      "size": [
        422.84503173828125,
        164.31304931640625
      ],
      "flags": {},
      "order": 5,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 74
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "slot_index": 0,
          "links": [
            46
          ]
        }
      ],
      "title": "CLIP Text Encode (Positive Prompt)",
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "Node name for S&R": "CLIPTextEncode"
      },
      "widgets_values": [
        "Create an image of four cats sitting on a wooden floor, arranged in a row and facing the camera.\n\nThe cats have different breeds and colors, showcasing a variety of fur patterns and expressions. From left to right:\n\nThe first cat has light brown and white fur, with floppy ears and a friendly expression.\nThe second cat has golden-orange fur with a fluffy coat, looking curious and alert.\nThe third cat has black and white fur, possibly resembling a tuxedo pattern, with striking eyes and a calm demeanor.\nThe fourth cat has a mix of orange and white fur, with perked-up ears and an attentive gaze.\nIn front of the cats, there is a GoPro camera placed on the wooden floor. The camera is positioned centrally, slightly angled toward the viewer, with its lens and brand logo clearly visible.\n\nThe background features a bright blue wall with soft lighting, giving the scene a cheerful and vibrant atmosphere. The overall mood of the image is playful and engaging, highlighting the curiosity and charm of the cats as they look at the camera."
      ],
      "color": "#232",
      "bgcolor": "#353"
    }
  ],
  "links": [
    [
      46,
      6,
      0,
      3,
      1,
      "CONDITIONING"
    ],
    [
      52,
      7,
      0,
      3,
      2,
      "CONDITIONING"
    ],
    [
      74,
      38,
      0,
      6,
      0,
      "CLIP"
    ],
    [
      75,
      38,
      0,
      7,
      0,
      "CLIP"
    ],
    [
      76,
      39,
      0,
      8,
      1,
      "VAE"
    ],
    [
      107,
      58,
      0,
      3,
      3,
      "LATENT"
    ],
    [
      110,
      8,
      0,
      60,
      0,
      "IMAGE"
    ],
    [
      125,
      66,
      0,
      3,
      0,
      "MODEL"
    ],
    [
      126,
      37,
      0,
      66,
      0,
      "MODEL"
    ],
    [
      128,
      3,
      0,
      8,
      0,
      "LATENT"
    ]
  ],
  "groups": [],
  "config": {},
  "extra": {
    "ds": {
      "scale": 1,
      "offset": [
        -815.4160387531228,
        -214.19249043190945
      ]
    },
    "frontendVersion": "1.23.4"
  },
  "version": 0.4
}